{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a599cc33",
   "metadata": {},
   "source": [
    "# 1.4 Propagation\n",
    "\n",
    "In the tutorial of spikingjelly ([https://spikingjelly.readthedocs.io/zh_CN/latest/activation_based_en/basic_concept.html](https://spikingjelly.readthedocs.io/zh_CN/latest/activation_based_en/basic_concept.html), they provide the concept of single timestep and multiple time-step.\n",
    "\n",
    "However, since we always use mutiple timesteps, I will focus on using them in this.\n",
    "\n",
    "Note: the downside of mutipletimesteps is large memory footprint and you may want to switch to single if needed.\n",
    "\n",
    "The outputs of single and multiple timesteps are IDENTICAL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c966092f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net=Sequential(\n",
      "  (0): Linear(in_features=8, out_features=4, bias=True)\n",
      "  (1): IFNode(\n",
      "    v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=s, backend=torch\n",
      "    (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "  )\n",
      "  (2): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (3): IFNode(\n",
      "    v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=s, backend=torch\n",
      "    (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "  )\n",
      ")\n",
      "y_seq_layer_by_layer=\n",
      "tensor([[[1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from spikingjelly.activation_based import neuron, functional, layer\n",
    "T = 4\n",
    "N = 2\n",
    "C = 8\n",
    "x_seq = torch.rand([T, N, C]) * 256.\n",
    "\n",
    "net = nn.Sequential(\n",
    "    layer.Linear(C, 4),\n",
    "    neuron.IFNode(),\n",
    "    layer.Linear(4, 2),\n",
    "    neuron.IFNode()\n",
    ")\n",
    "\n",
    "print(f'net={net}')\n",
    "\n",
    "\n",
    "functional.set_step_mode(net, step_mode='m')\n",
    "with torch.no_grad():\n",
    "    y_seq_layer_by_layer = x_seq\n",
    "    #for i in range(net.__len__()):\n",
    "    #    y_seq_layer_by_layer = net[i](y_seq_layer_by_layer)\n",
    "    y_seq_layer_by_layer = net(y_seq_layer_by_layer)\n",
    "    \n",
    "\n",
    "    print(f'y_seq_layer_by_layer=\\n{y_seq_layer_by_layer}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c661c49d",
   "metadata": {},
   "source": [
    "Same code with step by step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7024f1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net=Sequential(\n",
      "  (0): Linear(in_features=8, out_features=4, bias=True)\n",
      "  (1): IFNode(\n",
      "    v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=s, backend=torch\n",
      "    (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "  )\n",
      "  (2): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (3): IFNode(\n",
      "    v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=s, backend=torch\n",
      "    (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "  )\n",
      ")\n",
      "y_seq_step_by_step=\n",
      "tensor([[[1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [1., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "functional.set_step_mode(net, step_mode='s')\n",
    "print(f'net={net}')\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_seq_step_by_step = []\n",
    "    for t in range(T):\n",
    "        x = x_seq[t]\n",
    "        y = net(x)\n",
    "        y_seq_step_by_step.append(y.unsqueeze(0))\n",
    "    y_seq_step_by_step = torch.cat(y_seq_step_by_step, 0)\n",
    "\n",
    "    print(f'y_seq_step_by_step=\\n{y_seq_step_by_step}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59d2c8c",
   "metadata": {},
   "source": [
    "Let's compare two results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d071e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_error=0.0\n"
     ]
    }
   ],
   "source": [
    "max_error = (y_seq_layer_by_layer - y_seq_step_by_step).abs().max()\n",
    "print(f'max_error={max_error}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
